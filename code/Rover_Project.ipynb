{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rover Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had problems with JupyterNotebooks while importing some libraries, so i decided to continue and use PyCharm!\n",
    "My images and outputs are in the /output folder, together with the video!\n",
    "\n",
    "So, it goes through all the steps from the notebook given to us as guidance, but since i used an IDE i did not have the luxury to use Ipython previleges. What i did, as i went step by step, and plotet all the methods! The at the end i populated the process_image() method and made a movie with moviepy.\n",
    "\n",
    "So, here we go..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing first, importing libraries!\n",
    "OpenCV for warping and manipulating with images, Numpy is the one library that you esentially use evevrytime you do math with python, Matlotlib for ploting images, Pandas for reading files and creating data(arrays, lists), and lastly the Moveipy to export the data as vide file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from moviepy.editor import ImageSequenceClip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Databucket Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a class that takes data from the images we saved during training mode with RoboSIM. It uses pandas to create a dataframe where we sepcify the location of those images and the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../run_two/robot_log.csv')\n",
    "csv_img_list = df[\"Path\"].tolist()\n",
    "ground_truth = mpimg.imread('../calibration_images/map_bw.png')\n",
    "ground_truth_3d = np.dstack((ground_truth*0, ground_truth*255, ground_truth*0)).astype(np.float)\n",
    "\n",
    "class Databucket():\n",
    "    def __init__(self):\n",
    "        self.images = csv_img_list\n",
    "        self.xpos = df[\"X_Position\"].values\n",
    "        self.ypos = df[\"Y_Position\"].values\n",
    "        self.yaw = df[\"Yaw\"].values\n",
    "        self.count = -5\n",
    "        self.worldmap = np.zeros((200, 200, 3)).astype(np.float)\n",
    "        self.ground_truth = ground_truth_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the prespective transform class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use openCV finctions Warp getPerspectiveTransform() and warpPerspective() to map a pixel from camera to a 10cm sauqred in real world and then warping it as it is seen from top of rover (kindof radar/lidar/sonar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perspect_transform(img, src, dst):\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]))  # keep same size as input image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source & Destination picture transform methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the mapping of above finctions. So in order to do warping we need the surce pixels (as seen  from the camera on the rover) and the destination.\n",
    "Well, this step is done in the process_image() function, but as i explained, i used an IDE and it was better code managing to make a methods for it and just call it from process_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sour():\n",
    "    return np.float32([[14, 140], [301, 140], [200, 96], [118, 96]])\n",
    "def dest(img, dst_size, bottom_offset):\n",
    "    return np.float32([[img.shape[1] / 2 - dst_size, img.shape[0] - bottom_offset],\n",
    "                              [img.shape[1] / 2 + dst_size, img.shape[0] - bottom_offset],\n",
    "                              [img.shape[1] / 2 + dst_size, img.shape[0] - 2 * dst_size - bottom_offset],\n",
    "                              [img.shape[1] / 2 - dst_size, img.shape[0] - 2 * dst_size - bottom_offset],])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of most important function is this, as all the braind of the robot is based on color thresholding! So, we make some functions that will be used to not only determine the terrain and path, but also the rocks and other obstacles. All this based on color of pixels that will see through the camera on the rover!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_terrain(img):\n",
    "    color_select = np.zeros_like(img[:,:,0])\n",
    "    above_thresh = (img[:,:,0] > 160) \\\n",
    "                & (img[:,:,1] > 160) \\\n",
    "                & (img[:,:,2] > 160)\n",
    "    color_select[above_thresh] = 1\n",
    "    return color_select\n",
    "def color_obstcls(img):\n",
    "    color_select = np.zeros_like(img[:,:,0])\n",
    "    above_thresh = (img[:,:,0] < 160) \\\n",
    "                & (img[:,:,1] < 160) \\\n",
    "                & (img[:,:,2] < 160)\n",
    "    color_select[above_thresh] = 1\n",
    "    return color_select\n",
    "def color_rocks(img):\n",
    "    lower_thresh = np.array([20, 100, 100])\n",
    "    upper_thresh = np.array([25, 255, 255])\n",
    "    color_select = cv2.inRange(cv2.cvtColor(img, cv2.COLOR_RGB2HSV, 3), lower_thresh, upper_thresh)\n",
    "    return color_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping the terrain to world cordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rover_coords(binary_img):\n",
    "    ypos, xpos = binary_img.nonzero()\n",
    "    x_pixel = np.absolute(ypos - binary_img.shape[0]).astype(np.float)\n",
    "    y_pixel = -(xpos - binary_img.shape[0]).astype(np.float)\n",
    "    return x_pixel, y_pixel\n",
    "\n",
    "def rotate_pix(xpix, ypix, yaw):\n",
    "    yaw_rad = yaw * np.pi / 180\n",
    "    xpix_rotated = (xpix * np.cos(yaw_rad)) - (ypix * np.sin(yaw_rad))\n",
    "    ypix_rotated = (xpix * np.sin(yaw_rad)) + (ypix * np.cos(yaw_rad))\n",
    "    return xpix_rotated, ypix_rotated\n",
    "\n",
    "def translate_pix(xpix_rot, ypix_rot, xpos, ypos, scale):\n",
    "    xpix_translated = (xpix_rot / scale) + xpos\n",
    "    ypix_translated = (ypix_rot / scale) + ypos\n",
    "    return xpix_translated, ypix_translated\n",
    "\n",
    "def pix_to_world(xpix, ypix, xpos, ypos, yaw, world_size, scale):\n",
    "    xpix_rot, ypix_rot = rotate_pix(xpix, ypix, yaw)\n",
    "    xpix_tran, ypix_tran = translate_pix(xpix_rot, ypix_rot, xpos, ypos, scale)\n",
    "    x_pix_world = np.clip(np.int_(xpix_tran), 0, world_size - 1)\n",
    "    y_pix_world = np.clip(np.int_(ypix_tran), 0, world_size - 1)\n",
    "    return x_pix_world, y_pix_world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Angle and Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Afer we have calculated the x and y positions of navigable terrain pixels in rover space and now we'd like to decide which direction to steer the rover, and to do so, we use Polar Cordinates, as it is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_polar_coords(x_pixel, y_pixel):\n",
    "    dist = np.sqrt(x_pixel**2 + y_pixel**2)\n",
    "    angles = np.arctan2(y_pixel, x_pixel)\n",
    "    return dist, angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Export method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a method, that takes images as input (one per time) and makes them together as moveie. Using moviepy :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def video_export(process_image):\n",
    "    output = '../output/test_mapping.mp4'\n",
    "    clip = ImageSequenceClip(data.images, fps=60)\n",
    "    new_clip = clip.fl_image(process_image)\n",
    "    new_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# The processing method!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process_image() mathod, is the most iportant one here, as it takes a simple image, and makes all the necesary processing and outputs another image composed of four windowed processed images!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    cam_offset = 6\n",
    "    world_scale = 10\n",
    "    world_size = data.worldmap.shape[0]\n",
    "    #1\n",
    "    source = sour()\n",
    "    destination = dest(img, world_scale, cam_offset)\n",
    "    #2\n",
    "    warped = perspect_transform(img, source, destination)\n",
    "    #3\n",
    "    terrain_select = color_terrain(warped)\n",
    "    obstcls_select = color_obstcls(warped)\n",
    "    rocks_select = color_rocks(warped)\n",
    "    #4\n",
    "    terrain_xpix, terrain_ypix = rover_coords(terrain_select)\n",
    "    obstcls_xpix, oobstcls_ypix = rover_coords(obstcls_select)\n",
    "    rocks_xpix, rocks_ypix = rover_coords(rocks_select)\n",
    "    #5\n",
    "    xpos, ypos, yaw = data.xpos[data.count], data.ypos[data.count], data.yaw[data.count]\n",
    "    terrain_x_world, terrain_y_world = pix_to_world(terrain_xpix, terrain_ypix, xpos, ypos, yaw, world_size, world_scale)\n",
    "    obstcls_x_world, obstcls_y_world = pix_to_world(obstcls_xpix, oobstcls_ypix, xpos, ypos, yaw, world_size, world_scale)\n",
    "    rocks_x_world, rocks_y_world = pix_to_world(rocks_xpix, rocks_ypix, xpos, ypos, yaw, world_size, world_scale)\n",
    "    #6\n",
    "    data.worldmap[terrain_y_world, terrain_x_world, 0] += 1\n",
    "    data.worldmap[obstcls_y_world, obstcls_x_world, 2] += 1\n",
    "    data.worldmap[rocks_y_world, rocks_x_world, 1] += 1\n",
    "\n",
    "    mymap = data.worldmap.copy()\n",
    "    mymap[(data.worldmap[:, :, 0] > 1), 0] = 255\n",
    "    mymap[(data.worldmap[:, :, 2] > 20), 2] = 255\n",
    "    mymap[(data.worldmap[:, :, 1] > 1), 1] = 255\n",
    "    \n",
    "    dist, angles = to_polar_coords(terrain_xpix, terrain_ypix)\n",
    "    mean_dir = np.mean(angles)\n",
    "\n",
    "    output_image = np.zeros((img.shape[0] + data.worldmap.shape[0], img.shape[1] * 2, 3))\n",
    "    # Next you can populate regions of the image with various output\n",
    "    # Here I'm putting the original image in the upper left hand corner\n",
    "    output_image[0:img.shape[0], 0:img.shape[1]] = img\n",
    "    # Let's create more images to add to the mosaic, first a warped image\n",
    "    warped = perspect_transform(img, source, destination)\n",
    "    # Add the warped image in the upper right hand corner\n",
    "    output_image[0:img.shape[0], img.shape[1]:] = warped\n",
    "    # Overlay worldmap with ground truth map\n",
    "    map_add = cv2.addWeighted(mymap, 1, data.ground_truth, 0.5, 0)\n",
    "    # Flip map overlay so y-axis points upward and add to output_image\n",
    "    output_image[img.shape[0]:, 0:data.worldmap.shape[1]] = np.flipud(map_add)\n",
    "    output_image[img.shape[0]:img.shape[0] * 2, img.shape[1]:] = np.dstack((obstcls_select * 255,) * 3)\n",
    "\n",
    "    data.count += 1  # Keep track of the index in the Databucket()\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instanciate an data class that makes us ready the images with pandas dataset, and then those data are passed to vide_export() that takes those images and passes through process_image() function, and outputs a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Databucket()\n",
    "video_export(process_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
